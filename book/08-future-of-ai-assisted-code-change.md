# The Future of AI-Assisted Code Change

## Trends and predictions

AI is going to be embedded deeper into the software development lifecycle. As AI models become more sophisticated, they will not only assist in writing code but also in understanding complex systems, predicting potential issues, and suggesting architectural improvements. There will be a wider gamut of developers from non development background who Vibe code with AI doing the heavy lifting to Professional developers who will be able to wield AI to create more complex systems with less effort.

I predict that AI coding agents will become more autonomous, capable of making decisions based on the context of the project and the preferences of the development team. However this will not replace human developers who will be essential to guide, review, refine and ensure the AI contributions are aligned with the business and customer needs.

The speed of development is increasing, and with AI tooling it will accelerate further. This will mean that the SDLC ( Software Development Life Cycle ) will need to adapt to integrate AI contributions and the speed of change. There are some unknowns here that will need to be worked out, such as attribution of AI vs human contributions possibly to the word level? How to maintain code quality when the changes are so rapid? How to manage merge conflicts when AI Agents are making changes in parallel with human developers across multiple overlapping features? to name a few.

## Evolving best practices

Getting AI to work well with large scale code changes requires more meticulous approach to working with AI and testing tools to ensure the changes do not effect the quality of the codebase or changes the business logic in unexpected ways.

Remembering that the downside of high test coverage is that changes to functionality requires a lot of tests to change as well. In traditional software development this is often given as a higher cost of change if the test coverage is high and used to justify a mid level of test coverage. However with AI tooling the cost of change is not as high as it was before so the balance of test coverage vs cost of change is shifting. The benefits of high test coverage are more important with AI assistance to ensure that the AI generated code is functioning as expected and does not introduce regressions.

On the topic of cost of change, Documentation is more important than ever too, but now as part of the code itself. Again with the cost of code change being lower because of AI tooling, the cost of maintaining documentation is also lower. Further with better documentation the AI tooling is able to understand the codebase better and produce better results by only considering the relevant context of the problem at hand.

Working on smaller code changes is also more important than ever. The limitations of LLM token windows means that large code changes are only viable by breaking it down into smaller chunks and having good documentation helps the AI tools to understand the codebase to work on those smaller chunks. This is a shift from the traditional approach of trying to do large code changes in one go to maintain flow and momentum. With AI like with many agile teams it is better to work in smaller chunks, with more clarity and certainty, then iterating quicker rather than trying to make huge leaps in one prompt.


